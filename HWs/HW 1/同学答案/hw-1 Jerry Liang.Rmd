---
title: "Stat 432 Homework 1(Jerry Liang)"
date: "Assigned: Aug 26, 2024; <span style='color:red'>Due: 11:59 PM CT, Sep 5, 2024</span>"
output:
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
  pdf_document:
    toc: yes
    toc_depth: 2
---

<style>
  body {
  text-align: justify}
</style>

```{css, echo=FALSE}
  .solution {
  background-color: #CCDDFF; /* Replace with your desired color */
  }
  
  blockquote {
  background-color: #CCDDFF; /* Replace with your desired color */
  font-family: "Times New Roman", serif; /* Change to your desired font family */
  /* font-size: 16px; /* Change to your desired font size */
  font-weight: bold; /* Makes the text bold */
  }
```


## Question 1 (Multivariate Normal Distribution)

This question is about playing with AI tools for generating multivariate normal random variables. Let $X_i$, $i = 1, \ldots, n$ be i.i.d. multivariate normal random variables with mean $\mu$ and covariance matrix $\Sigma$, where 
$$ 
\mu = \begin{bmatrix} 1 \\ 2 \end{bmatrix}, \quad \text{and} \quad \Sigma = \begin{bmatrix} 1 & 0.5 \\ 0.5 & 1 \end{bmatrix}.
$$
Write `R` code to perform the following tasks. Please try to use AI tools as much as possible in this question. 

a. [10 points] Generate a set of $n = 2000$ observations from this distribution. Only display the first 5 observations in your `R` output. Make sure set random seed $=1$ in order to replicate the result. Calculate the sample covariance matrix of the generated data and compare it with the true covariance matrix $\Sigma$.
```{r}
library(tidyverse)
set.seed(1)
library(MASS)
mu <- c(0, 0)
Sigma <- matrix(c(1, 0.5, 0.5, 1), nrow = 2)
n <- 2000
data <- mvrnorm(n, mu, Sigma)
head(data, 5)
sample_cov <- cov(data)
sample_cov
Sigma
difference <- sample_cov - Sigma
difference
```
b. [10 points] If you used VS Code and AI tools to perform the previous question, then they will most likely suggest using the `mvrnorm` function from the `MASS` package. However, there are alternative ways to complete this question. For example, you could first generate $n$ standard normal random variables, and then transform them to the desired distribution. Write down the mathematical formula of this approach in Latex, and then write `R` code to implement this approach. Only display the first 5 observations in your `R` output. Validate your approach by computing the sample covariance matrix of the generated data and compare it with the true covariance matrix $\Sigma$. Please note that you __should not use__ the `mvrnorm` function anymore in this question. 
$$
 Z \sim \mathcal{N}(0, I_n)\\
 
 \Sigma \in \mathbb{R}^{n \times n}, \quad \Sigma = A A^\top\\
 
 X = \mu + A Z\\
 
 X \sim \mathcal{N}(\mu, \Sigma)\\
 
 \mu = (0,...,0) \\
$$
```{r}
set.seed(1)
Sigma = matrix(c(1, 0.5, 0.5, 1), ncol = 2)

A = chol(Sigma)


n=2000
Z = matrix(rnorm(2 * n), ncol = 2, nrow=n)

X = Z %*% A

head(X, 5)

sample_cov = cov(X)
Sigma
sample_cov
Sigma - sample_cov
```

c. [10 points] Write an `R` function called `mymvnorm` that takes the following arguments: `n`, `mu`, `sigma`. The function should return a matrix of dimension $n \times p$, where $p$ is the length of `mu`. The function should generate $n$ observations from a multivariate normal distribution with mean `mu` and covariance matrix `sigma`. You should not use the `mvrnorm` function in your code. Instead, use the logic you wrote in part b) to generate the data. Again, validate your result by calculating the sample covariance matrix of the generated data and compare to $\Sigma$. Also, when setting seed correctly, your answer in this question should be identical to the one in part b).
```{r}
mymvnorm <- function(n, mu, sigma) {

  mu <- as.vector(mu)

  p <- length(mu)
  
  A <- chol(sigma)
  
  Z <- matrix(rnorm(n * p), ncol = p)

  X <- Z %*% A + matrix(rep(mu, each = n), ncol = p, byrow = TRUE)
  
  return(X)
}


set.seed(1)
n <- 2000
mu <- c(0, 0)
sigma <- matrix(c(1, 0.5, 0.5, 1), ncol = 2)

X1 <- mymvnorm(n, mu, sigma)

sample_cov <- cov(X1)

print("True covariance matrix:")
print(sigma)

print("Sample covariance matrix:")
print(sample_cov)

print("Difference between true and sample covariance matrix:")
print(sigma - sample_cov)
```
d. [10 points] If you used any AI tools during the first three questions, write your experience here. Specifically, what tool(s) did you use? __What prompt was used__? Did the tool suggested a corrected answer to your question? If not, which part was wrong? How did you corrected their mistakes (e.g modifying your prompt)?

```{r}
#I write question a and question c using chatgpt. The answer is seemingly write in part A, I just copy and paste the question a to chatgpt. Part B looks tricky since it asked me to provide mathmatical formula, so I write it myself and ask chatgpt to repeat my work in part B as a function. The result of C is the same as B so I assume it is correct
```
## Question 2 (Data Manipulation Plots)

The following question practices data manipulation and summary statistics. Our goal is to write a function that calculates the price gap between any two given dates. Load the `quantmod` package and obtain the `AAPL` data (apple stock price). 

```{r class.source="solution", warning=FALSE, message=FALSE, fig.align='center', out.width='60%'}
  library(quantmod)
  getSymbols("AAPL")
  plot(AAPL$AAPL.Close, pch = 19)
```

a. [20 points] Calculate a 90-day moving average of the closing price of `AAPL` and plot it on the same graph. Moving average means that for each day, you take the average of the previous 90 days. Please do this in two ways: 1) there is a built-in function called `SMA` in the `quantmod` package; 2) write your own function to calculate the moving average. For both questions, you can utilize AI tools to help you write the code.
```{r}
aapl_close <- Cl(AAPL)  # Extract the closing prices
aapl_SMA <- SMA(AAPL$AAPL.Close, n = 90)

# Plot the closing prices and the moving average
plot(aapl_close, main = "AAPL Closing Prices with 90-Day SMA", col = "blue")
lines(aapl_SMA, col = "red", lwd = 2)
legend("topright", legend = c("Closing Price", "90-Day SMA"), col = c("blue", "red"), lty = 1, lwd = 2)
```
```{r}
AAPL_df <- data.frame(Date = index(AAPL), Close_Price = coredata(AAPL$AAPL.Close))
moving_average <- function(x) {
  ma <- c()
  for (i in 1:length(x)) {
    if (i >= 90) {
      ma[i] <- sum(x[(i-89):i]) / 90
    } else {
      ma[i] <- sum(x[1:i]) / i
    }
  }
  return(ma)
}


aapl_custom_SMA <- moving_average(AAPL_df$AAPL.Close)
aapl_custom_SMA_df <- data.frame(Date = AAPL_df$Date, AAPL.Close = aapl_custom_SMA)
aapl_custom_SMA_xts <- xts(aapl_custom_SMA_df$AAPL.Close, order.by = as.Date(aapl_custom_SMA_df$Date))

plot(aapl_close, main = "AAPL Closing Prices with 90-Day Custom Moving Average", col = "blue")
lines(aapl_custom_SMA_xts, col = "red",lwd=3)
```

b. [15 points] I have an alternative way of writing this function. 

```{r class.source="solution", fig.align='center', out.width='60%'}
  my_average <- function(x, window) {
    # Compute the moving average of x with window size = window
    n <- length(x)
    ma <- rep(NA, n)
    for (i in window:n) {
      myinterval = (i-window/2):(i + window/2)
      myinterval = myinterval[myinterval > 0 & myinterval <= n]
      ma[i] <- mean( x[ myinterval ] )
    }
    return(ma)
  }

  AAPL$MA90 <- my_average(Cl(AAPL), 90)
  plot(AAPL$AAPL.Close, pch = 19)
  lines(AAPL$MA90, col = "red", lwd = 3)
```

Can you comment on the difference of these two functions? Do you think my line is a good choice when it is used for predicting future prices? Which one do you prefer and why.
```{r}
#My function uses the past 90 observations, which results in a trailing average that reflects historical data leading up to the current point. Your function takes half of the observations from before and half from after the current point, centering the moving average around it. SMA is a lagging indicator, using it solely to predict price is like driving while looking in the rearview mirror. Therefore none of the line by itself is a good choice for predicting future prices. However, in the sense of checking trend, yours could be better since it provides smoother result. 
```

## Question 3 (Read/write Data)

a. [10 Points] The `ElemStatLearn` package [[CRAN link](https://cran.r-project.org/web/packages/ElemStatLearn/index.html)] is an archived package. Hence, you cannot directly install it using the `install.packages()` function. Instead, you may install an older version of it by using the `install_github()` function from the `devtools` package. Install the `devtools` package and run the find the code to install the `ElemStatLearn` package.
```{r}
library(devtools)
##install_github("cran/ElemStatLearn")
```

b. [15 Points] Load the `ElemStatLearn` package and obtain the `ozone` data. Save this data into a `.csv` file, and then read the data back from that file into `R`. Print out the first 5 observations to make sure that the new data is the same as the original one.
```{r}
library(ElemStatLearn)

data(ozone)

write.csv(ozone, "ozone_data.csv", row.names = FALSE)

ozone_data <- read.csv("ozone_data.csv")


head(ozone, 5)
head(ozone_data, 5)
```