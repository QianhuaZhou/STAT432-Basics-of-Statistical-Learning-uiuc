# Load necessary library
library(glmnet)
# Step 1: Prepare the data for glmnet
# Use the top 250 pixels from part a) for logistic regression with elastic net penalty
X_train <- as.matrix(train_data_filtered[, -1])  # Exclude the Digit column
y_train <- train_data_filtered$Digit  # Convert labels to binary (1 for '5', 0 for '4')
# Step 2: Fit logistic regression with elastic net penalty (alpha = 0.5)
elastic_net_model <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5)
# Step 3: Identify the lambda that corresponds to a model with exactly 30 variables
# Check the number of non-zero coefficients for each lambda
num_nonzero <- apply(coef(elastic_net_model), 2, function(coef) sum(coef != 0))
# Find the lambda value that corresponds to exactly 30 non-zero coefficients
lambda_30 <- elastic_net_model$lambda[which(non_zero_counts == 30)][1] # 31 because of intercept
# Load necessary library
library(glmnet)
# Step 1: Prepare the data for glmnet
# Use the top 250 pixels from part a) for logistic regression with elastic net penalty
X_train <- as.matrix(train_data_filtered[, -1])  # Exclude the Digit column
y_train <- train_data_filtered$Digit
# Convert labels to binary (1 for '5', 0 for '4')
y_train<- ifelse(y_train == 5, 1, 0)
# Step 2: Fit logistic regression with elastic net penalty (alpha = 0.5)
elastic_net_model <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5)
plot(elastic_net_model, xvar = "lambda", label = TRUE)
# Step 3: Identify the lambda that corresponds to a model with exactly 30 variables
# Check the number of non-zero coefficients for each lambda
num_nonzero <- apply(coef(elastic_net_model), 2, function(coef) sum(coef != 0))
# Find the lambda value that corresponds to exactly 30 non-zero coefficients
lambda_30 <- elastic_net_model$lambda[which(num_nonzero == 31)]  # 31 because of intercept
# Step 4: Refit the model using this lambda value and extract the selected pixels
coef_30 <- coef(elastic_net_model, s = lambda_30)  # Get the coefficients at lambda_30
selected_pixels_elastic_net <- which(coef_30[-1] != 0)  # Exclude the intercept
# Step 5: Compare to the top 30 pixels selected by the SVM
overlap_pixels <- intersect(selected_pixels_elastic_net, top_30_indices)
# Print the results
cat("Lambda value for 30-variable model: ", lambda_30, "\n")
cat("Selected pixels from Elastic Net: ", selected_pixels_elastic_net, "\n")
cat("Overlap with SVM-selected pixels: ", overlap_pixels, "\n")
# Load necessary library
library(glmnet)
# Step 1: Prepare the data for glmnet
# Use the top 250 pixels from part a) for logistic regression with elastic net penalty
X_train <- as.matrix(train_data_filtered[, -1])  # Exclude the Digit column
y_train <- train_data_filtered$Digit
# Convert labels to binary (1 for '5', 0 for '4')
y_train<- ifelse(y_train == 5, 1, 0)
# Step 2: Fit logistic regression with elastic net penalty (alpha = 0.5)
elastic_net_model <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5)
plot(elastic_net_model, xvar = "lambda", label = TRUE)
# Load necessary library
library(glmnet)
# Step 1: Prepare the data for glmnet
# Use the top 250 pixels from part a) for logistic regression with elastic net penalty
X_train <- as.matrix(train_data_filtered[, -1])  # Exclude the Digit column
y_train <- train_data_filtered$Digit
# Convert labels to binary (1 for '5', 0 for '4')
y_train<- ifelse(y_train == 5, 1, 0)
# Step 2: Fit logistic regression with elastic net penalty (alpha = 0.5)
elastic_net_model <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5)
# Step 3: Identify the lambda that corresponds to a model with exactly 30 variables
# Check the number of non-zero coefficients for each lambda
num_nonzero <- apply(coef(elastic_net_model), 2, function(coef) sum(coef != 0))
# Find the lambda value that corresponds to exactly 30 non-zero coefficients
lambda_30 <- elastic_net_model$lambda[which(num_nonzero == 31)]  # 31 because of intercept
# Step 4: Refit the model using this lambda value and extract the selected pixels
coef_30 <- coef(elastic_net_model, s = lambda_30)  # Get the coefficients at lambda_30
selected_pixels_elastic_net <- rownames(coef_30)[which(coef_30 != 0)][-1] # Exclude the intercept
# Step 5: Compare to the top 30 pixels selected by the SVM
overlap_pixels <- intersect(selected_pixels_elastic_net, top_30_indices)
# Print the results
cat("Lambda value for 30-variable model: ", lambda_30, "\n")
cat("Selected pixels from Elastic Net: ", selected_pixels_elastic_net, "\n")
cat("Overlap with SVM-selected pixels: ", overlap_pixels, "\n")
cat("Overlapping Pixels between SVM and Elastic Net:\n", overlap, "\n")
# Load necessary library
library(glmnet)
# Step 1: Prepare the data for glmnet
# Use the top 250 pixels from part a) for logistic regression with elastic net penalty
X_train <- as.matrix(train_data_filtered[, -1])  # Exclude the Digit column
y_train <- train_data_filtered$Digit
# Convert labels to binary (1 for '5', 0 for '4')
y_train<- ifelse(y_train == 5, 1, 0)
# Step 2: Fit logistic regression with elastic net penalty (alpha = 0.5)
elastic_net_model <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5)
# Step 3: Identify the lambda that corresponds to a model with exactly 30 variables
# Check the number of non-zero coefficients for each lambda
num_nonzero <- apply(coef(elastic_net_model), 2, function(coef) sum(coef != 0))
# Find the lambda value that corresponds to exactly 30 non-zero coefficients
lambda_30 <- elastic_net_model$lambda[which(num_nonzero == 31)]  # 31 because of intercept
# Step 4: Refit the model using this lambda value and extract the selected pixels
coef_30 <- coef(elastic_net_model, s = lambda_30)  # Get the coefficients at lambda_30
selected_pixels_elastic_net <- rownames(coef_30)[which(coef_30 != 0)][-1] # Exclude the intercept
# Step 5: Compare to the top 30 pixels selected by the SVM
overlap_pixels <- intersect(selected_pixels_elastic_net, top_30_indices)
# Print the results
cat("Lambda value for 30-variable model: ", lambda_30, "\n")
cat("Selected pixels from Elastic Net: ", selected_pixels_elastic_net, "\n")
cat("Overlap with SVM-selected pixels: ", overlap_pixels, "\n")
cat("Overlapping Pixels between SVM and Elastic Net:\n", overlap_pixels, "\n")
selected_pixels_elastic_net
overlap_pixels
# Step 1: Extract the coefficients from the fitted linear SVM model
svm_coefs <- svm_filtered$coefs  # The coefficients for the support vectors
support_vectors <- svm_filtered$SV  # The support vectors themselves
# Calculate the overall coefficients (beta) for each pixel
# Matrix multiplication of the coefficients and the support vectors
beta <- t(svm_coefs) %*% support_vectors
# Step 2: Find the top 30 pixels with the largest absolute coefficients
# Get absolute values of the coefficients
beta_abs <- abs(beta)
# Sort by the largest absolute coefficients and get the indices of the top 30 pixels
top_30_indices <- order(beta_abs, decreasing = TRUE)[1:30]
top_30_pixels <- colnames(train_data_filtered)[-1][top_30_indices]
cat("Top 30 Important Pixels: \n", top_30_pixels, "\n")
# Step 3: Refit the SVM using only these 30 pixels
train_data_top30 <- train_data_filtered[, c(1, top_30_indices + 1)]  # Include the digit column
test_data_top30 <- test_data_filtered[, c(1, top_30_indices + 1)]
# Fit a new SVM model using just these 30 pixels
svm_top30 <- svm(Digit ~ ., data = train_data_top30, kernel = "linear", cost = 1)
# Make predictions and calculate errors
train_pred_top30 <- predict(svm_top30, train_data_top30)
test_pred_top30 <- predict(svm_top30, test_data_top30)
train_error_top30 <- mean(train_pred_top30 != train_data_top30$Digit)
test_error_top30 <- mean(test_pred_top30 != test_data_top30$Digit)
# Print the training and testing errors for the top 30 pixel model
cat("Training Error (Top 30 Pixels): ", train_error_top30, "\n")
cat("Testing Error (Top 30 Pixels): ", test_error_top30, "\n")
# Load necessary library
library(glmnet)
# Step 1: Prepare the data for glmnet
# Use the top 250 pixels from part a) for logistic regression with elastic net penalty
X_train <- as.matrix(train_data_filtered[, -1])  # Exclude the Digit column
y_train <- train_data_filtered$Digit
# Convert labels to binary (1 for '5', 0 for '4')
y_train<- ifelse(y_train == 5, 1, 0)
# Step 2: Fit logistic regression with elastic net penalty (alpha = 0.5)
elastic_net_model <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5)
# Step 3: Identify the lambda that corresponds to a model with exactly 30 variables
# Check the number of non-zero coefficients for each lambda
num_nonzero <- apply(coef(elastic_net_model), 2, function(coef) sum(coef != 0))
# Find the lambda value that corresponds to exactly 30 non-zero coefficients
lambda_30 <- elastic_net_model$lambda[which(num_nonzero == 31)]  # 31 because of intercept
# Step 4: Refit the model using this lambda value and extract the selected pixels
coef_30 <- coef(elastic_net_model, s = lambda_30)  # Get the coefficients at lambda_30
selected_pixels_elastic_net <- rownames(coef_30)[which(coef_30 != 0)][-1] # Exclude the intercept
# Step 5: Compare to the top 30 pixels selected by the SVM
overlap_pixels <- intersect(selected_pixels_elastic_net, top_30_indices)
# Print the results
cat("Lambda value for 30-variable model: ", lambda_30, "\n")
cat("Selected pixels from Elastic Net: ", selected_pixels_elastic_net, "\n")
cat("Overlap with SVM-selected pixels: ", overlap_pixels, "\n")
cat("Overlapping Pixels between SVM and Elastic Net:\n", overlap_pixels, "\n")
# Step 5: Compare to the top 30 pixels selected by the SVM
overlap_pixels <- intersect(selected_pixels_elastic_net, top_30_indices)
overlap_pixels
top_30_pixels <- colnames(train_data_filtered)[-1][top_30_indices]
cat("Top 30 Important Pixels: \n", top_30_pixels, "\n")
# Load necessary library
library(glmnet)
# Step 1: Prepare the data for glmnet
# Use the top 250 pixels from part a) for logistic regression with elastic net penalty
X_train <- as.matrix(train_data_filtered[, -1])  # Exclude the Digit column
y_train <- train_data_filtered$Digit
# Convert labels to binary (1 for '5', 0 for '4')
y_train<- ifelse(y_train == 5, 1, 0)
# Step 2: Fit logistic regression with elastic net penalty (alpha = 0.5)
elastic_net_model <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5)
# Step 3: Identify the lambda that corresponds to a model with exactly 30 variables
# Check the number of non-zero coefficients for each lambda
num_nonzero <- apply(coef(elastic_net_model), 2, function(coef) sum(coef != 0))
# Find the lambda value that corresponds to exactly 30 non-zero coefficients
lambda_30 <- elastic_net_model$lambda[which(num_nonzero == 31)]  # 31 because of intercept
# Step 4: Refit the model using this lambda value and extract the selected pixels
coef_30 <- coef(elastic_net_model, s = lambda_30)  # Get the coefficients at lambda_30
selected_pixels_elastic_net <- rownames(coef_30)[which(coef_30 != 0)][-1] # Exclude the intercept
# Step 5: Compare to the top 30 pixels selected by the SVM
overlap_pixels <- intersect(selected_pixels_elastic_net, top_30_pixels)
# Print the results
cat("Lambda value for 30-variable model: ", lambda_30, "\n")
cat("Selected pixels from Elastic Net: ", selected_pixels_elastic_net, "\n")
cat("Overlap with SVM-selected pixels: ", overlap_pixels, "\n")
cat("Overlapping Pixels between SVM and Elastic Net:\n", length(overlap_pixels), "\n")
library(pROC)
library(glmnet)
# Step 1: Prepare the data for glmnet
X_train <- as.matrix(train_data_filtered[, -1])  # Exclude the Digit column
y_train <- as.numeric(train_data_filtered$Digit == 5)  # Convert labels to binary (1 for '5', 0 for '4')
# Step 2: Fit logistic regression with elastic net penalty (alpha = 0.5)
elastic_net_model <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5)
# Step 3: Identify the lambda that corresponds to a model with exactly 30 variables
# Check the number of non-zero coefficients for each lambda
num_nonzero <- apply(coef(elastic_net_model), 2, function(coef) sum(coef != 0))
# Find the lambda value that corresponds to exactly 30 non-zero coefficients
lambda_30 <- elastic_net_model$lambda[which(num_nonzero == 31)]  # 31 because of intercept
# Step 4: Refit the model using this lambda value and extract the selected pixels
elastic_net_selected <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5, lambda = lambda_30)
# Prepare the test data
X_test <- as.matrix(test_data_filtered[, -1])  # Test data with the top 250 pixels from part a)
y_test <- as.numeric(test_data_filtered$Digit == 5)  # Binary response for test data
# Step 1: Predictions for SVM model with top 30 pixels
svm_pred_prob <- attr(predict(svm_top30, test_data_top30, decision.values = TRUE), "decision.values")
# Step 2: Predictions for Elastic Net model
enet_pred_prob <- predict(elastic_net_selected, X_test, type = "response")
# Step 3: Calculate AUC for SVM model
roc_svm <- roc(y_test, svm_pred_prob)
auc_svm <- auc(roc_svm)
cat("AUC for SVM model: ", auc_svm, "\n")
# Step 4: Calculate AUC for Elastic Net model
roc_enet <- roc(y_test, enet_pred_prob)
auc_enet <- auc(roc_enet)
cat("AUC for Elastic Net model: ", auc_enet, "\n")
# Comparison
if (auc_svm > auc_enet) {
cat("SVM model performs better with a higher AUC.\n")
} else {
cat("Elastic Net model performs better with a higher AUC.\n")
}
plot(roc_svm, col = "blue", main = "ROC Curves for SVM and Elastic Net Models", lwd = 2)
plot(elastic_net_model, xvar = "lambda", label = TRUE)
par(mar = c(5, 5, 4, 2) + 0.1)
plot(elastic_net_model, xvar = "lambda", label = TRUE)
par(mar = c(5, 5, 4, 2\)
par(mar = c(5, 5, 4, 2)
plot(elastic_net_model, xvar = "lambda", label = TRUE)
elastic_net_model <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5)
par(mar = c(5, 5, 4, 2))
plot(elastic_net_model, xvar = "lambda", label = TRUE)
library(pROC)
library(glmnet)
# Step 1: Prepare the data for glmnet
X_train <- as.matrix(train_data_filtered[, -1])  # Exclude the Digit column
y_train <- as.numeric(train_data_filtered$Digit == 5)  # Convert labels to binary (1 for '5', 0 for '4')
# Step 2: Fit logistic regression with elastic net penalty (alpha = 0.5)
elastic_net_model <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5)
# Step 3: Identify the lambda that corresponds to a model with exactly 30 variables
# Check the number of non-zero coefficients for each lambda
num_nonzero <- apply(coef(elastic_net_model), 2, function(coef) sum(coef != 0))
# Find the lambda value that corresponds to exactly 30 non-zero coefficients
lambda_30 <- elastic_net_model$lambda[which(num_nonzero == 31)]  # 31 because of intercept
# Step 4: Refit the model using this lambda value and extract the selected pixels
elastic_net_selected <- glmnet(X_train, y_train, family = "binomial", alpha = 0.5, lambda = lambda_30)
# Prepare the test data
X_test <- as.matrix(test_data_filtered[, -1])  # Test data with the top 250 pixels from part a)
y_test <- as.numeric(test_data_filtered$Digit == 5)  # Binary response for test data
# Step 1: Predictions for SVM model with top 30 pixels
svm_pred_prob <- attr(predict(svm_top30, test_data_top30, decision.values = TRUE), "decision.values")
# Step 2: Predictions for Elastic Net model
enet_pred_prob <- predict(elastic_net_selected, X_test, type = "response")
# Step 3: Calculate AUC for SVM model
roc_svm <- roc(y_test, svm_pred_prob)
auc_svm <- auc(roc_svm)
cat("AUC for SVM model: ", auc_svm, "\n")
# Step 4: Calculate AUC for Elastic Net model
roc_enet <- roc(y_test, enet_pred_prob)
auc_enet <- auc(roc_enet)
cat("AUC for Elastic Net model: ", auc_enet, "\n")
# Comparison
if (auc_svm > auc_enet) {
cat("SVM model performs better with a higher AUC.\n")
} else {
cat("Elastic Net model performs better with a higher AUC.\n")
}
plot(roc_svm, col = "blue", main = "ROC Curves for SVM and Elastic Net Models", lwd = 2)
library(ISLR2)
data("OJ")
set.seed(7)
id=sample(nrow(OJ),800)
train=OJ[id,]
test=OJ[-id,]
# Load necessary libraries
library(e1071)
library(ISLR2)
# Load the data
data("OJ")
# Set a seed for reproducibility
set.seed(7)
# Split the data into training and test sets
id = sample(nrow(OJ), 800)
train = OJ[id, ]
test = OJ[-id, ]
# Fit a linear SVM model with cost = 0.01
svm_model <- svm(Purchase ~ ., data = train, kernel = "linear", cost = 0.01)
# Predict on training data
train_pred <- predict(svm_model, train)
train_error <- mean(train_pred != train$Purchase)
# Predict on test data
test_pred <- predict(svm_model, test)
test_error <- mean(test_pred != test$Purchase)
# Output the errors
cat("Training Error: ", train_error, "\n")
cat("Test Error: ", test_error, "\n")
# Load necessary libraries
library(e1071)
library(ISLR2)
# Load the data
data("OJ")
# Set a seed for reproducibility
set.seed(7)
# Split the data into training and test sets
id = sample(nrow(OJ), 800)
train = OJ[id, ]
test = OJ[-id, ]
# Tune the SVM model to find the best cost
tune_result <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
# Best model
best_model <- tune_result$best.model
# Compute training and test errors with the best model
train_pred_best <- predict(best_model, train)
train_error_best <- mean(train_pred_best != train$Purchase)
test_pred_best <- predict(best_model, test)
test_error_best <- mean(test_pred_best != test$Purchase)
# Output the best cost, training error, and test error
cat("Best Cost: ", tune_result$best.parameters$cost, "\n")
cat("Training Error with Best Cost: ", train_error_best, "\n")
cat("Test Error with Best Cost: ", test_error_best, "\n")
library(ISLR2)
data("OJ")
set.seed(7)
id=sample(nrow(OJ),800)
train=OJ[id,]
test=OJ[-id,]
library(ISLR2)
data("OJ")
set.seed(7)
id=sample(nrow(OJ),800)
train=OJ[id,]
test=OJ[-id,]
# Tune the SVM model to find the best cost
tune_result <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
# Best model
best_model <- tune_result$best.model
# Compute training and test errors with the best model
train_pred_best <- predict(best_model, train)
train_error_best <- mean(train_pred_best != train$Purchase)
test_pred_best <- predict(best_model, test)
test_error_best <- mean(test_pred_best != test$Purchase)
# Output the best cost, training error, and test error
cat("Best Cost: ", tune_result$best.parameters$cost, "\n")
cat("Training Error with Best Cost: ", train_error_best, "\n")
cat("Test Error with Best Cost: ", test_error_best, "\n")
# Load necessary libraries
library(e1071)
library(ISLR2)
# Split the data into training and test sets
train = OJ[id, ]
test = OJ[-id, ]
# Fit a linear SVM model with cost = 0.01
svm_model <- svm(Purchase ~ ., data = train, kernel = "linear", cost = 0.01)
# Predict on training data
train_pred <- predict(svm_model, train)
train_error <- mean(train_pred != train$Purchase)
# Predict on test data
test_pred <- predict(svm_model, test)
test_error <- mean(test_pred != test$Purchase)
# Output the errors
cat("Training Error: ", train_error, "\n")
cat("Test Error: ", test_error, "\n")
library(ISLR2)
data("OJ")
set.seed(7)
id=sample(nrow(OJ),800)
train=OJ[id,]
test=OJ[-id,]
set.seed(7)
tune_linear = tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
best_linear_model = tune_linear$best.model
best_cost = tune_linear$best.parameters$cost
best_cost
library(ISLR2)
data("OJ")
set.seed(7)
id=sample(nrow(OJ),800)
train=OJ[id,]
test=OJ[-id,]
tune_result <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
# Compute training and test errors with the best model
train_pred_best <- predict(best_model, train)
# Best model
best_model <- tune_result$best.model
best_cost = tune_linear$best.parameters$cost
# Output the best cost, training error, and test error
cat("Best Cost: ", tune_result$best.parameters$cost, "\n")
best_cost = tune_linear$best.parameters$cost
# Tune the SVM model to find the best cost
tune_result <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
# Best model
best_model <- tune_result$best.model
# Compute training and test errors with the best model
train_pred_best <- predict(best_model, train)
train_error_best <- mean(train_pred_best != train$Purchase)
test_pred_best <- predict(best_model, test)
test_error_best <- mean(test_pred_best != test$Purchase)
# Output the best cost, training error, and test error
cat("Best Cost: ", best_model$best.parameters$cost, "\n")
cat("Training Error with Best Cost: ", train_error_best, "\n")
cat("Test Error with Best Cost: ", test_error_best, "\n")
# Output the best cost, training error, and test error
cat("Best Cost: ", tune_result$best.parameters$cost, "\n")
# Tune the SVM model to find the best cost
tune_result <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
# Best model
best_model <- tune_result$best.model
# Compute training and test errors with the best model
train_pred_best <- predict(best_model, train)
train_error_best <- mean(train_pred_best != train$Purchase)
test_pred_best <- predict(best_model, test)
test_error_best <- mean(test_pred_best != test$Purchase)
# Output the best cost, training error, and test error
cat("Best Cost: ", tune_result$best.parameters$cost, "\n")
cat("Training Error with Best Cost: ", train_error_best, "\n")
cat("Test Error with Best Cost: ", test_error_best, "\n")
# Tune the SVM model to find the best cost
tune_result <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
# Best model
best_model <- tune_result$best.model
# Compute training and test errors with the best model
train_pred_best <- predict(best_model, train)
train_error_best <- mean(train_pred_best != train$Purchase)
test_pred_best <- predict(best_model, test)
test_error_best <- mean(test_pred_best != test$Purchase)
# Output the best cost, training error, and test error
cat("Best Cost: ", tune_result$best.parameters$cost, "\n")
cat("Training Error with Best Cost: ", train_error_best, "\n")
cat("Test Error with Best Cost: ", test_error_best, "\n")
library(ISLR2)
data("OJ")
set.seed(7)
id=sample(nrow(OJ),800)
train=OJ[id,]
test=OJ[-id,]
# Tune the SVM model to find the best cost
tune_result <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
# Best model
best_model <- tune_result$best.model
# Compute training and test errors with the best model
train_pred_best <- predict(best_model, train)
train_error_best <- mean(train_pred_best != train$Purchase)
test_pred_best <- predict(best_model, test)
test_error_best <- mean(test_pred_best != test$Purchase)
# Output the best cost, training error, and test error
cat("Best Cost: ", tune_result$best.parameters$cost, "\n")
cat("Training Error with Best Cost: ", train_error_best, "\n")
cat("Test Error with Best Cost: ", test_error_best, "\n")
set.seed(7)
tune_linear <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
# Print the best model and cost
best_model_linear <- tune_linear$best.model
cat("Best Cost for Linear SVM:", tune_linear$best.parameters$cost, "\n")
# Tune the SVM model to find the best cost
tune_result <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
# Best model
best_model <- tune_result$best.model
# Compute training and test errors with the best model
train_pred_best <- predict(best_model, train)
train_error_best <- mean(train_pred_best != train$Purchase)
test_pred_best <- predict(best_model, test)
test_error_best <- mean(test_pred_best != test$Purchase)
# Output the best cost, training error, and test error
cat("Best Cost: ", tune_result$best.parameters$cost, "\n")
cat("Training Error with Best Cost: ", train_error_best, "\n")
cat("Test Error with Best Cost: ", test_error_best, "\n")
set.seed(7)
# Tune the SVM model to find the best cost
tune_result <- tune(svm, Purchase ~ ., data = train, kernel = "linear",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
# Best model
best_model <- tune_result$best.model
# Compute training and test errors with the best model
train_pred_best <- predict(best_model, train)
train_error_best <- mean(train_pred_best != train$Purchase)
test_pred_best <- predict(best_model, test)
test_error_best <- mean(test_pred_best != test$Purchase)
# Output the best cost, training error, and test error
cat("Best Cost: ", tune_result$best.parameters$cost, "\n")
cat("Training Error with Best Cost: ", train_error_best, "\n")
cat("Test Error with Best Cost: ", test_error_best, "\n")
set.seed(7)
# Radial Kernel SVM with tuning for cost
tune_result_radial <- tune(svm, Purchase ~ ., data = train, kernel = "radial",
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
best_model_radial <- tune_result_radial$best.model
# Predict and calculate errors for radial kernel
train_pred_radial <- predict(best_model_radial, train)
train_error_radial <- mean(train_pred_radial != train$Purchase)
test_pred_radial <- predict(best_model_radial, test)
test_error_radial <- mean(test_pred_radial != test$Purchase)
# Polynomial Kernel (degree 2) SVM with tuning for cost
tune_result_poly <- tune(svm, Purchase ~ ., data = train, kernel = "polynomial", degree = 2,
ranges = list(cost = c(0.01, 0.1, 1, 2, 5, 7, 10)))
best_model_poly <- tune_result_poly$best.model
# Predict and calculate errors for polynomial kernel
train_pred_poly <- predict(best_model_poly, train)
train_error_poly <- mean(train_pred_poly != train$Purchase)
test_pred_poly <- predict(best_model_poly, test)
test_error_poly <- mean(test_pred_poly != test$Purchase)
# Output the errors for radial and polynomial kernels
cat("Radial Kernel - Best Cost: ", tune_result_radial$best.parameters$cost, "\n")
cat("Radial Kernel - Training Error: ", train_error_radial, "\n")
cat("Radial Kernel - Test Error: ", test_error_radial, "\n\n")
cat("Polynomial Kernel (degree 2) - Best Cost: ", tune_result_poly$best.parameters$cost, "\n")
cat("Polynomial Kernel (degree 2) - Training Error: ", train_error_poly, "\n")
cat("Polynomial Kernel (degree 2) - Test Error: ", test_error_poly, "\n")
