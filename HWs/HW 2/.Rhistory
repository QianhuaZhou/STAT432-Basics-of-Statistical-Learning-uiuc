realestate = read.csv("realestate.csv", row.names = 1)
test_idx = sample(nrow(realestate), 100)
train_idx = setdiff(1:nrow(realestate), test_idx)
train_data <- realestate[train_idx, ]
test_data <- realestate[test_idx, ]
# Fit the full model with all covariates in the training data
full_model <- lm(price ~ ., data = train_data)
# Perform stepwise selection using the AIC criterion
selected_model <- step(full_model, direction = "both", k = 2)
summary(selected_model)
# Calculate the training error for the selected model
y_train_hat <- predict(selected_model, newdata = train_data)
train_error <- mean((train_data$price - y_train_hat)^2)
cat("Training Error:", train_error, "\n")
# Calculate the testing error for the selected model
y_test_hat <- predict(selected_model, newdata = test_data)
test_error <- mean((test_data$price - y_test_hat)^2)
cat("Testing Error:", test_error, "\n")
set.seed(432)
test_ids = sample(nrow(realestate), 100)
test_data <- realestate[test_ids, ]
train_data <- realestate[-test_ids, ]
X_train <- cbind(1, train_data$age, train_data$distance, train_data$stores)
y_train <- train_data$price
X_test <- cbind(1, test_data$age, test_data$distance, test_data$stores)
y_test <- test_data$price
# Linear regression coefficients for training data
beta_hat <- solve(t(X_train) %*% X_train) %*% t(X_train) %*% y_train
y_train_pred <- X_train %*% beta_hat
y_test_pred <- X_test %*% beta_hat
training_error <- mean((y_train - y_train_pred)^2)
testing_error <- mean((y_test - y_test_pred)^2)
cat("training_error: ", training_error, "\n")
cat("testing_error: ", testing_error, "\n")
set.seed(432)
test_ids = sample(nrow(realestate), 100)
test_data <- realestate[test_ids, ]
train_data <- realestate[-test_ids, ]
X_train <- cbind(1, train_data$age, train_data$distance, train_data$stores)
y_train <- train_data$price
X_test <- cbind(1, test_data$age, test_data$distance, test_data$stores)
y_test <- test_data$price
# Linear regression coefficients for training data
beta_hat <- solve(t(X_train) %*% X_train) %*% t(X_train) %*% y_train
y_train_pred <- X_train %*% beta_hat
y_test_pred <- X_test %*% beta_hat
training_error <- mean((y_train - y_train_pred)^2)
testing_error <- mean((y_test - y_test_pred)^2)
cat("training_error: ", training_error, "\n")
cat("testing_error: ", testing_error, "\n")
set.seed(432)
test_ids = sample(nrow(realestate), 100)
realestate = read.csv("realestate.csv", row.names = 1)
test_idx = sample(nrow(realestate), 100)
train_idx = setdiff(1:nrow(realestate), test_idx)
train_data <- realestate[train_idx, ]
test_data <- realestate[test_idx, ]
# Fit the full model with all covariates in the training data
full_model <- lm(price ~ ., data = train_data)
# Perform stepwise selection using the AIC criterion
selected_model <- step(full_model, direction = "both", k = 2)
summary(selected_model)
# Calculate the training error for the selected model
y_train_hat <- predict(selected_model, newdata = train_data)
train_error <- mean((train_data$price - y_train_hat)^2)
cat("Training Error:", train_error, "\n")
# Calculate the testing error for the selected model
y_test_hat <- predict(selected_model, newdata = test_data)
test_error <- mean((test_data$price - y_test_hat)^2)
cat("Testing Error:", test_error, "\n")
set.seed(432)
full_model <- lm(price ~ age + distance + stores, data = train_data)
stepwise_model <- step(full_model, direction = "both")
summary(stepwise_model)
train_predictions <- predict(stepwise_model, newdata = train_data)
training_error <- mean((train_data$price - train_predictions)^2)
cat("Training Error:", training_error, "\n")
test_predictions <- predict(stepwise_model, newdata = test_data)
testing_error <- mean((test_data$price - test_predictions)Ë†2)
set.seed(432)
full_model <- lm(price ~ age + distance + stores, data = train_data)
stepwise_model <- step(full_model, direction = "both")
summary(stepwise_model)
train_predictions <- predict(stepwise_model, newdata = train_data)
training_error <- mean((train_data$price - train_predictions)^2)
cat("Training Error:", training_error, "\n")
test_predictions <- predict(stepwise_model, newdata = test_data)
testing_error <- mean((test_data$price - test_predictions)^2)
cat("Testing Error:", testing_error, "\n")
# Fit the full model with all covariates in the training data
full_model <- lm(price ~ ., data = train_data)
# Perform stepwise selection using the AIC criterion
selected_model <- step(full_model, direction = "both", k = 2)
summary(selected_model)
# Calculate the training error for the selected model
y_train_hat <- predict(selected_model, newdata = train_data)
train_error <- mean((train_data$price - y_train_hat)^2)
cat("Training Error:", train_error, "\n")
# Calculate the testing error for the selected model
y_test_hat <- predict(selected_model, newdata = test_data)
test_error <- mean((test_data$price - y_test_hat)^2)
cat("Testing Error:", test_error, "\n")
full_model <- lm(price ~ age + distance + stores, data = train_data)
stepwise_model <- step(full_model, direction = "both")
summary(stepwise_model)
train_predictions <- predict(stepwise_model, newdata = train_data)
training_error <- mean((train_data$price - train_predictions)^2)
cat("Training Error:", training_error, "\n")
test_predictions <- predict(stepwise_model, newdata = test_data)
testing_error <- mean((test_data$price - test_predictions)^2)
cat("Testing Error:", testing_error, "\n")
library(leaps)
set.seed(1)
n <- 100
p <- 20
X <- matrix(rnorm(n * p), nrow = n, ncol = p)
epsilon <- rnorm(n)
Y <- 1/2 * X[,1] + 1/4 * X[,2] + 1/8 * X[,3] + 1/16 * X[,4] + epsilon
subset_selection <- regsubsets(Y ~ ., data = as.data.frame(X), nvmax = p)
model_summary <- summary(subset_selection)
AIC_values <- n * log(model_summary$rss / n) + 2 * (1:p + 1)
best_model_index <- which.min(AIC_values)
best_model <- model_summary$which[best_model_index,]
selected_variables <- names(best_model[best_model == TRUE])
selected_variables <- selected_variables[selected_variables != "(Intercept)"]
selected_variables
best_model_coef <- coef(subset_selection, id = best_model_index)
best_model <- as.formula(paste("Y ~", paste(selected_variables, collapse = " + ")))
best_model_fit <- lm(best_model, data = as.data.frame(X))
best_fitted_values <- predict(best_model_fit)
error <- (Y - best_fitted_values)^2
mean(error)
# Define the training and testing data
train_data <- realestate[train_idx, ]
test_data <- realestate[test_idx, ]
# Fit the full model with all covariates in the training data
full_model <- lm(price ~ ., data = train_data)
# Perform stepwise selection using the AIC criterion
selected_model <- step(full_model, direction = "both", k = 2)
summary(selected_model)
# Calculate the training error for the selected model
y_train_hat <- predict(selected_model, newdata = train_data)
train_error <- mean((train_data$price - y_train_hat)^2)
cat("Training Error:", train_error, "\n")
# Calculate the testing error for the selected model
y_test_hat <- predict(selected_model, newdata = test_data)
test_error <- mean((test_data$price - y_test_hat)^2)
cat("Testing Error:", test_error, "\n")
set.seed(432)
test_idx = sample(nrow(realestate), 100)
train_idx = setdiff(1:nrow(realestate), test_idx)
# Define the training and testing data
train_data <- realestate[train_idx, ]
test_data <- realestate[test_idx, ]
# Fit the full model with all covariates in the training data
full_model <- lm(price ~ ., data = train_data)
# Perform stepwise selection using the AIC criterion
selected_model <- step(full_model, direction = "both", k = 2)
summary(selected_model)
# Calculate the training error for the selected model
y_train_hat <- predict(selected_model, newdata = train_data)
train_error <- mean((train_data$price - y_train_hat)^2)
cat("Training Error:", train_error, "\n")
# Calculate the testing error for the selected model
y_test_hat <- predict(selected_model, newdata = test_data)
test_error <- mean((test_data$price - y_test_hat)^2)
cat("Testing Error:", test_error, "\n")
set.seed(432)
test_idx = sample(nrow(realestate), 100)
train_idx = setdiff(1:nrow(realestate), test_idx)
# Define the training and testing data
train_data <- realestate[train_idx, ]
test_data <- realestate[test_idx, ]
# Fit the full model with all covariates in the training data
full_model <- lm(price ~ ., data = train_data)
# Perform stepwise selection using the AIC criterion
selected_model <- step(full_model, direction = "both", k = 2)
summary(selected_model)
# Calculate the training error for the selected model
y_train_hat <- predict(selected_model, newdata = train_data)
train_error <- mean((train_data$price - y_train_hat)^2)
cat("Training Error:", train_error, "\n")
# Calculate the testing error for the selected model
y_test_hat <- predict(selected_model, newdata = test_data)
test_error <- mean((test_data$price - y_test_hat)^2)
cat("Testing Error:", test_error, "\n")
result1 <- optim(par = c(0, 0), fn = f_obj, method = "BFGS")
