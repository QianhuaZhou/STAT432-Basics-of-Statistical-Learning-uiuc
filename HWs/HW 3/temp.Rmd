---
title: "Untitled"
author: "Qianhua Zhou"
date: "2024-09-19"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
  a. [25 points] We will not use this data for classification (the original problem). Instead, we will do a toy regression example to show how genes are highly correlated and could be used to predict each. Carry out the following tasks:

      * Perform marginal association test for each gene with the response `golub.cl` using `mt.teststat()`. Use `t.equalvar` (two sample $t$ test with equal variance) as the test statistic. 
      * Sort the genes by their p-values and select the top 100 genes
      * Construct a dataset with the top 10 genes and another one (call it $X$) with the remaining genes
      * Perform principal component analysis (PCA) on the top 100 genes and extract the first principal component, __use this as the outcome $y$__. Becareful about the oriantation of the data matrix. 
      * Perform ridge regression with 19-fold cross-validation on $X$ and the outcome $y$. Does your model fit well? Can you provide detailed model fitting results to support your claim?
      * Fit ridge regression but use GCV as the criterion. Does your model fit well?
```{r, message = FALSE}
#if (!requireNamespace("BiocManager", quietly = TRUE)) {
#    install.packages("BiocManager")
#}
#BiocManager::install("multtest")
library(multtest)
```
```{r}
data(golub)
# Perform marginal association test (t-test with equal variance)
test_stat <- mt.teststat(golub, golub.cl, test = "t.equalvar")
# Calculate p-values from test statistics
p_values <- 2 * pt(-abs(test_stat), df = length(golub.cl) - 2)
# Sort the genes by p-values and select the top 100
top_100_genes <- order(p_values)[1:100]

# Dataset with top 10 genes
golub_top_10 <- golub[top_100_genes[1:10], ]
# Dataset with remaining 90 genes (for ridge regression)
X <- golub[top_100_genes[11:100], ]

# Perform PCA on the top 100 genes
pca_result <- prcomp(t(golub[top_100_genes, ]))  # Transpose is required
# Extract the first principal component
y <- pca_result$x[, 1]

library(glmnet)
# Ridge regression with 19-fold cross-validation
cv_ridge <- cv.glmnet(t(X), y, alpha = 0, nfolds = 19)
# Plot the cross-validation curve
par(mar = c(2.5, 2.5, 2, 1) + 0.1)
plot(cv_ridge)
cat("Best lambda:", cv_ridge$lambda.min, "\n")
# Fit the ridge regression model using the best lambda
ridge_model <- glmnet(t(X), y, alpha = 0, lambda = cv_ridge$lambda.min)
# Output model fitting results
coef(ridge_model)
cv_mse <- min(cv_ridge$cvm)
cv_mse
var(y)

# Ridge regression using GCV (Generalized Cross-Validation)
ridge_gcv <- glmnet(t(X), y, alpha = 0, lambda = cv_ridge$lambda.min, type.measure = "gcv")
# Check model coefficients for GCV-based fit
coef(ridge_gcv)
```



```{r class.source="solution", message=FALSE, eval=FALSE}
    # Load required library
    library(MASS)
    library(glmnet)
    
    # Simulate data with multicollinearity
    set.seed(42)
    n <- 100
    p <- 10
    X <- matrix(rnorm(n * p), n, p)
    X[,2] <- X[,1] + rnorm(n) * 0.01 # Introducing multicollinearity
    beta <- runif(p)
    y <- X %*% beta + rnorm(n)
    
    # Ordinary Linear Regression
    lm_model <- lm(y ~ X)
    lm_pred <- predict(lm_model, newdata=data.frame(X=X))
    
    # Ridge Regression
    ridge_model <- glmnet(X, y, alpha=0)
    ridge_pred <- predict(ridge_model, s=0.01, newx=X)
    
    # Compare Performance
    lm_mse <- mean((y - lm_pred)^2)
    ridge_mse <- mean((y - ridge_pred)^2)
    
    cat("MSE of Ordinary Linear Regression:", lm_mse, "\n")
    cat("MSE of Ridge Regression:", ridge_mse, "\n")
```

#liheng Q2
```{r}
library(glmnet)
data(golub)
# Step 1: Perform t-test for marginal association (genes with class labels)
t_statistics <- mt.teststat(golub, golub.cl, test = "t.equalvar")
# Step 2: Calculate p-values from t-statistics and select top 100 genes
pvals <- 2 * pnorm(-abs(t_statistics)) # Calculate p-values
sorted_gene_indices <- order(pvals) # Sort genes by p-value
top_gene_indices <- sorted_gene_indices[1:100] # Top 100 genes
# Step 3: Separate top 10 genes and remaining genes
top_gene_data <- golub[top_gene_indices, ] # Data for top 100 genes
top_10_genes_data <- top_gene_data[1:10, ] # Top 10 genes
remaining_genes_data <- top_gene_data[11:100, ] # Remaining 90 genes (for X)
# Step 4: Perform PCA on the top 100 genes and extract first component
pca_output <- prcomp(t(top_gene_data), scale. = TRUE)
response_y <- pca_output$x[, 1] # First principal component as outcome y
# Step 5: Ridge Regression with 19-Fold Cross-Validation
X <- t(remaining_genes_data) # Transpose remaining gene data (rows as samples)
cv_control <- 19 # Set cross-validation folds
ridge_cv_model <- cv.glmnet(X, response_y, nfolds = cv_control, alpha = 0)
# Step 6: Extract and plot the results
optimal_lambda <- ridge_cv_model$lambda.min # Best lambda value
print(optimal_lambda)
# Predictions based on best lambda
y_predicted <- predict(ridge_cv_model, X, s = optimal_lambda)
# Mean Squared Error (MSE)
mse_value <- mean((response_y - y_predicted)^2)
print(mse_value)
# Plots
plot(ridge_cv_model)
plot(ridge_cv_model$glmnet.fit, xvar = "lambda", label = TRUE)
# Step 7: Ridge Regression using GCV Criterion
library(MASS)
ridge_gcv_fit <- lm.ridge(response_y ~ ., data = as.data.frame(X), lambda = seq(0, 100, by = 0.5))
# Plot GCV values
plot(ridge_gcv_fit$lambda, ridge_gcv_fit$GCV, type = "l", col = "blue", lwd = 2,
ylab = "GCV", xlab = "Lambda")
title("GCV Plot for Ridge Regression")
# Best lambda based on GCV
best_lambda_gcv <- ridge_gcv_fit$lambda[which.min(ridge_gcv_fit$GCV)]
print(best_lambda_gcv)
# Predictions based on GCV-selected lambda
X_matrix <- cbind(Intercept = 1, as.matrix(X))
y_predicted_gcv <- X_matrix %*% coef(ridge_gcv_fit)[which.min(ridge_gcv_fit$GCV),]
# MSE for GCV-based model
mse_gcv <- mean((response_y - y_predicted_gcv)^2)
print(mse_gcv)
```

1, also, mse is 2.938193e-06, very close to 0, the model is a good fit.
19-Fold Cross-Validation: In the first analysis, Ridge Regression was applied using 19-fold cross-validation on the dataset X (comprising the remaining 90 genes) and the outcome y (the first principal component of the top 100 genes). The results show that the optimal lambda value selected through cross-validation was 63.22, and the MSE for the predictions was 1.22. The cross-validation plot displayed a smooth curve, where the error increased as ff moved away from the optimal point, which suggests that the model effectively regularized the data. Given the relatively low MSE and the well-behaved CV error curve, the model fits well under these settings, providing a stable and effective prediction.

GCV Fit: In the second part of the analysis, Ridge Regression was fit using the Generalized Cross-Validation(GCV) criterion. The optimal lambda selected by GCV was 0.5, and the resulting MSE was extremelylow, with a value of 6.44e-5, suggesting a strong fit. The GCV plot showed a consistent increase in erroras ff increased, indicating that the model fits best with minimal regularization. Given the much lower MSEcompared to the 19-fold cross-validation approach, the GCV-based model appears to provide an even better fit, making it more effective at minimizing prediction error for this particular dataset.
