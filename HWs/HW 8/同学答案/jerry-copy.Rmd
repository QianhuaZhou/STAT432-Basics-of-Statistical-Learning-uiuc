---
title: "Stat 432 Homework 8"
date: "Assigned: Oct 14, 2024; <span style='color:red'>Due: 11:59 PM CT, Oct 24, 2024</span>"
output:
  pdf_document:
    toc: yes
    toc_depth: 2
  html_document:
    df_print: paged
    toc: yes
    toc_depth: '2'
---

<style>
  body {
  text-align: justify}
</style>

```{css, echo=FALSE}
  .solution {
  background-color: #CCDDFF; /* Replace with your desired color */
  }
  
  blockquote {
  background-color: #CCDDFF; /* Replace with your desired color */
  font-family: "Times New Roman", serif; /* Change to your desired font family */
  /* font-size: 16px; /* Change to your desired font size */
  font-weight: bold; /* Makes the text bold */
  }
```

# Question 1: Discriminant Analysis (60 points) 

We will be using the first 2500 observations of the MNIST dataset. You can use the following code, or the saved data from our previous homework.

```{r}
  # inputs to download file
  fileLocation <- "https://pjreddie.com/media/files/mnist_train.csv"
  numRowsToDownload <- 2500
  localFileName <- paste0("mnist_first", numRowsToDownload, ".RData")

  # download the data and add column names
  mnist <- read.csv(fileLocation, nrows = numRowsToDownload)
  numColsMnist <- dim(mnist)[2]
  colnames(mnist) <- c("Digit", paste("Pixel", seq(1:(numColsMnist - 1)), sep = ""))

  # save file
  # in the future we can read in from the local copy instead of having to redownload
  save(mnist, file = localFileName)
  
  # you can load the data with the following code
  load(file = localFileName)
```

  a. [10 pts] Write you own code to fit a Linear Discriminant Analysis (LDA) model to the MNIST dataset. Use the first 1250 observations as the training set and the remaining observations as the test set. An issue with this dataset is that some pixels display little or no variation across all observations. This zero variance issue poses a problem when inverting the estimated covariance matrix. To address this issue, take digits 1, 7, and 9 from the training data, and perform a screening on the marginal variance of all 784 pixels. Take the top 300 pixels with the largest variance and use them to fit the LDA model. Remove the remaining ones from the training and test data.
```{r}
library(MASS)  # For LDA
library(dplyr) # For data manipulation

load(file = "mnist_first2500.RData")

train_data <- mnist[1:1250, ]
test_data <- mnist[1251:2500, ]

train_filtered <- train_data %>% filter(Digit %in% c(1, 7, 9))

pixel_variances <- apply(train_filtered[, -1], 2, var)

top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]

train_selected <- train_filtered[, c(1, top_pixels + 1)] 
test_selected <- test_data[, c(1, top_pixels + 1)]
train_selected
lda_model <- lda(Digit ~ ., data = train_selected)

predictions <- predict(lda_model, newdata = test_selected)

accuracy <- mean(predictions$class == test_selected$Digit)
cat("LDA Model Accuracy:", accuracy * 100, "%\n")
```

  b. [30 pts] Write your own code to implement the LDA model. Remember that LDA requires the estimation of several parameters: $\Sigma$, $\mu_k$, and $\pi_k$. Estimate these parameters and calculate the decision scores $\delta_k$ on the testing data to predict the class label. Report the accuracy and the confusion matrix based on the testing data. 
```{r}
library(caret)
LDA_custom <- function(train_data, test_data) {
  classes <- unique(train_data$Digit)
  num_classes <- length(classes)
  mu_k <- train_data %>%
    group_by(Digit) %>%
    summarise_all(mean) %>%
    select(-Digit) %>%
    as.data.frame()
  cov_matrix <- cov(train_data[,-1]) 
  pi_k <- table(train_data$Digit) / nrow(train_data)
  delta_k <- function(x, k) {
    mu <- as.numeric(mu_k[k, ])
    pi <- pi_k[k]
    delta <- t(x) %*% solve(cov_matrix) %*% mu - 0.5 * t(mu) %*% solve(cov_matrix) %*% mu + log(pi)
    return(delta)
  }
  predict_LDA <- function(test_data) {
    predictions <- c()
    
    for (i in 1:nrow(test_data)) {
      x <- as.numeric(test_data[i, -1])
      delta_values <- sapply(1:num_classes, function(k) delta_k(x, k))
      predicted_class <- classes[which.max(delta_values)]
      predictions <- c(predictions, predicted_class)
    }
    
    return(predictions)
  }
  predictions <- predict_LDA(test_data)
  actual <- test_data$Digit
  accuracy <- mean(predictions == actual)
  conf_matrix <- confusionMatrix(factor(predictions), factor(actual))
  
  return(list(accuracy = accuracy, confusion_matrix = conf_matrix))
}

load(file = "mnist_first2500.RData")
train_data <- mnist[1:1250, ]
test_data <- mnist[1251:2500, ]

train_filtered <- train_data %>% filter(Digit %in% c(1, 7, 9))
test_filtered <- test_data %>% filter(Digit %in% c(1, 7, 9))

pixel_variances <- apply(train_filtered[, -1], 2, var)
top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]

train_selected <- train_filtered[, c(1, top_pixels + 1)]
test_selected <- test_filtered[, c(1, top_pixels + 1)]

results <- LDA_custom(train_selected, test_selected)

cat("Accuracy:", results$accuracy * 100, "%\n")
print(results$confusion_matrix)
```

  c. [10 pts] Use the `lda()` function from MASS package to fit LDA. Report the accuracy and the confusion matrix based on the testing data. Compare your results with part b.
```{r}
library(MASS) 

# Load the MNIST dataset and split into training and test sets
load(file = "mnist_first2500.RData")
train_data <- mnist[1:1250, ]
test_data <- mnist[1251:2500, ]

# Filter for digits 1, 7, and 9 from the training data
train_filtered <- train_data %>% filter(Digit %in% c(1, 7, 9))
test_filtered <- test_data %>% filter(Digit %in% c(1, 7, 9))

# Select the top 300 pixels with the largest variance
pixel_variances <- apply(train_filtered[, -1], 2, var)
top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]

# Subset the training and test data to retain only the selected pixels
train_selected <- train_filtered[, c(1, top_pixels + 1)]  # +1 to account for 'Digit' column
test_selected <- test_filtered[, c(1, top_pixels + 1)]

# Step 1: Fit the LDA model using the `lda()` function from MASS
lda_model <- lda(Digit ~ ., data = train_selected)

# Step 2: Make predictions on the test data
lda_predictions <- predict(lda_model, newdata = test_selected)

# Step 3: Calculate the accuracy
lda_accuracy <- mean(lda_predictions$class == test_selected$Digit)

# Step 4: Generate the confusion matrix
lda_conf_matrix <- confusionMatrix(factor(lda_predictions$class), factor(test_selected$Digit))

# Report the accuracy and confusion matrix
cat("LDA Model Accuracy (using MASS lda()):", lda_accuracy * 100, "%\n")
print(lda_conf_matrix)
```

  d. [10 pts] Use the `qda()` function from MASS package to fit QDA. Does the code work directly? Why? If you are asked to modify your own code to perform QDA, what would you do? Discuss this issue and propose at least two solutions to address it. If relavent, provide mathematical reasoning (in latex) of your solution. You __do not__ need to implement that with code. 
No, the code not work directly with the qda() function. One of the key reasons is that Quadratic Discriminant Analysis requires estimating a separate covariance matrix for each class. If there are issues such as zero or near-zero variance in the data, or if some features have very low variance, the QDA model might run into issues when attempting to invert the covariance matrix for each class. If I were asked to modify my own code, I would Introduce regularization by adding ridge parameter lambda.This helps avoid the singularity problem by making the covariance matrix invertible. 
$$
\Sigma_k' = \Sigma_k + \lambda I
$$
Another way to address the singular covariance issue is to perform feature selection or dimensionality reduction by removing features (pixels) that have near-zero variance.
Mathematically, this involves checking the determinant of each class-specific covariance matrix:
$$
|\Sigma_k| > 0
$$
In QDA, the class-specific covariance matrix Sigma_k is used to model the spread of the data for class k. The discriminant function for class k involves both the determinant Sigma_k and the inverse Sigma_k^{-1}:

$$
\delta_k(x) = -\frac{1}{2} \log|\Sigma_k| - \frac{1}{2}(x - \mu_k)^\top \Sigma_k^{-1} (x - \mu_k) + \log(\pi_k)
$$
If sigma_k = 0, the inverse Sigma_k^{-1} does not exist, and the discriminant function cannot be computed.

# Question 2: Regression Trees (40 points) 

Load data `Carseats` from the `ISLR` package. Use the following code to define the training and test sets.

```{r}
  # load library
  library(ISLR)
  
  # load data
  data(Carseats)
  
  # set seed
  set.seed(7)
  
  # number of rows in entire dataset
  n_Carseats <- dim(Carseats)[1]
  
  # training set parameters
  train_percentage <- 0.75
  train_size <- floor(train_percentage*n_Carseats)
  train_indices <- sample(x = 1:n_Carseats, size = train_size)
  
  # separate dataset into train and test
  train_Carseats <- Carseats[train_indices,]
  test_Carseats <- Carseats[-train_indices,]
```

  a. [20 pts] We seek to predict the variable `Sales` using a regression tree. Load the library `rpart`. Fit a regression tree to the training set using the `rpart()` function, all hyperparameter arguments should be left as default. Load the library `rpart.plot()`. Plot the tree using the `prp()` function. Based on this model, what type of observations has the highest or lowest sales? Predict using the tree onto the test set, calculate and report the MSE on the testing data.
```{r}
library(rpart)
library(rpart.plot)
tree_model <- rpart(Sales ~ ., data = train_Carseats)
prp(tree_model, type = 1, extra = 1)
predictions <- predict(tree_model, newdata = test_Carseats)
mse <- mean((predictions - test_Carseats$Sales)^2)
mse
summary(tree_model)
```
Price >= 110 and Compric<124 has the highest sales. Price>=106, SheiveLo=Bad,Populati<197,age<45 has the lowest sale.

  b. [20 pts] Set the seed to 7 at the beginning of the chunk and do this question in a single chunk so the seed doesn't get switched. Find the largest complexity parameter value of the tree you grew in part a) that will ensure that the cross-validation error < min(cross-validation error) + cross-validation standard deviation. Print that complexity parameter value. Prune the tree using that value. Predict using the pruned tree onto the test set, calculate the test Mean-Squared Error, and print it.
```{r}
set.seed(7)

library(rpart)
library(rpart.plot)

data(Carseats)
n_Carseats <- dim(Carseats)[1]
train_percentage <- 0.75
train_size <- floor(train_percentage * n_Carseats)
train_indices <- sample(1:n_Carseats, size = train_size)
train_Carseats <- Carseats[train_indices,]
test_Carseats <- Carseats[-train_indices,]

tree_model <- rpart(Sales ~ ., data = train_Carseats)

# Plot the tree
prp(tree_model, type = 1, extra = 1)

predictions <- predict(tree_model, newdata = test_Carseats)
mse_original <- mean((predictions - test_Carseats$Sales)^2)
mse_original


printcp(tree_model)

cp_table <- tree_model$cptable
min_xerror <- min(cp_table[,"xerror"])
xerror_threshold <- min_xerror + cp_table[which.min(cp_table[,"xerror"]),"xstd"]
optimal_cp <- max(cp_table[cp_table[,"xerror"] <= xerror_threshold,"CP"])
optimal_cp

pruned_tree <- prune(tree_model, cp = optimal_cp)

prp(pruned_tree, type = 1, extra = 1)


pruned_predictions <- predict(pruned_tree, newdata = test_Carseats)
mse_pruned <- mean((pruned_predictions - test_Carseats$Sales)^2)
mse_pruned
```

