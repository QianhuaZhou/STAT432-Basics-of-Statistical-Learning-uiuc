}
# Step 5: Full pipeline to fit LDA model and evaluate
run_lda <- function(train_data, test_data) {
# Estimate LDA parameters
params <- lda_parameters(train_data)
# Get predictions for the test set
predictions <- lda_predict(test_data, params$mu_k, params$Sigma, params$pi_k, unique(train_data$Digit))
# Evaluate and return accuracy and confusion matrix
results <- evaluate_predictions(test_data, predictions)
print(paste("Test Accuracy:", results$accuracy))
print("Confusion Matrix:")
print(results$confusion_matrix)
return(results)
}
# Preprocessing as in Part (a) to select top 300 pixels
pixel_variances <- apply(train_data_filtered[, -1], 2, var)
top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]
train_data_top_pixels <- train_data_filtered[, c(1, top_pixels + 1)]  # +1 for the 'Digit' column
test_data_top_pixels <- test_data_filtered[, c(1, top_pixels + 1)]
# Run LDA model
results <- run_lda(train_data_top_pixels, test_data_top_pixels)
# Load necessary libraries
library(MASS)
# Step 1: Parameter Estimation
lda_parameters <- function(train_data) {
# Separate data by class
classes <- unique(train_data$Digit)
K <- length(classes)
n <- nrow(train_data)
# Calculate priors pi_k
pi_k <- sapply(classes, function(k) mean(train_data$Digit == k))
# Calculate class means mu_k (store each class's mean as a column)
mu_k <- matrix(0, ncol = K, nrow = ncol(train_data) - 1)  # (number of pixels, number of classes)
colnames(mu_k) <- classes  # Set class labels as column names
for (k in 1:K) {
mu_k[, k] <- colMeans(train_data[train_data$Digit == classes[k], -1])
}
# Calculate shared covariance matrix Sigma (pooled covariance)
X_centered <- lapply(classes, function(k) {
class_data <- train_data[train_data$Digit == k, -1]
sweep(class_data, 2, mu_k[, k], "-") # Centering by class mean
})
Sigma <- Reduce("+", lapply(X_centered, function(X) t(X) %*% X)) / (n - K)
list(mu_k = mu_k, Sigma = Sigma, pi_k = pi_k, classes = classes)
}
# Step 2: Calculate Decision Scores
calculate_delta <- function(x, mu_k, Sigma_inv, pi_k, K) {
delta_k <- sapply(1:K, function(k) {
x %*% Sigma_inv %*% mu_k[, k] - 0.5 * t(mu_k[, k]) %*% Sigma_inv %*% mu_k[, k] + log(pi_k[k])
})
return(delta_k)
}
# Step 3: LDA prediction function
lda_predict <- function(test_data, mu_k, Sigma, pi_k, classes) {
K <- length(classes)
Sigma_inv <- solve(Sigma)
predictions <- apply(test_data[, -1], 1, function(x) {
delta_k <- calculate_delta(x, mu_k, Sigma_inv, pi_k, K)
classes[which.max(delta_k)] # Predict the class with the highest score
})
return(predictions)
}
# Step 4: Calculate accuracy and confusion matrix
evaluate_predictions <- function(test_data, predictions) {
confusion_matrix <- table(test_data$Digit, predictions)
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
list(accuracy = accuracy, confusion_matrix = confusion_matrix)
}
# Step 5: Full pipeline to fit LDA model and evaluate
run_lda <- function(train_data, test_data) {
# Estimate LDA parameters
params <- lda_parameters(train_data)
# Get predictions for the test set
predictions <- lda_predict(test_data, params$mu_k, params$Sigma, params$pi_k, params$classes)
# Evaluate and return accuracy and confusion matrix
results <- evaluate_predictions(test_data, predictions)
print(paste("Test Accuracy:", results$accuracy))
print("Confusion Matrix:")
print(results$confusion_matrix)
return(results)
}
# Preprocessing as in Part (a) to select top 300 pixels
pixel_variances <- apply(train_data_filtered[, -1], 2, var)
top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]
train_data_top_pixels <- train_data_filtered[, c(1, top_pixels + 1)]  # +1 for the 'Digit' column
test_data_top_pixels <- test_data_filtered[, c(1, top_pixels + 1)]
# Run LDA model
results <- run_lda(train_data_top_pixels, test_data_top_pixels)
# Select digits 1, 7, and 9
mnist_subset <- mnist[mnist$Digit %in% c(1, 7, 9), ]
# Calculate variance for each pixel
pixel_variances <- apply(mnist_subset[, -1], 2, var)
# Select the top 300 pixels with the highest variance
top_300_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]
# Subset the data to include only the selected pixels
train_data <- mnist_subset[1:1250, c(1, top_300_pixels + 1)] # Add 1 to skip the "Digit" column
test_data <- mnist[1251:2500, c(1, top_300_pixels + 1)]
# Function to calculate mean vectors
calculate_means <- function(data) {
tapply(1:nrow(data), data$Digit, function(idx) colMeans(data[idx, -1]))
}
# Calculate class means, priors, and covariance matrix
class_means <- calculate_means(train_data)
class_priors <- table(train_data$Digit) / nrow(train_data)
cov_matrix <- cov(train_data[, -1])
# LDA decision function to calculate scores
lda_decision_function <- function(x, mu, sigma_inv, prior) {
x %*% sigma_inv %*% mu - 0.5 * t(mu) %*% sigma_inv %*% mu + log(prior)
}
# Compute decision scores for test data
sigma_inv <- solve(cov_matrix)
scores <- sapply(1:3, function(k) lda_decision_function(as.matrix(test_data[, -1]),
class_means[[k]], sigma_inv, class_priors[k]))
# Corrected LDA decision function
lda_decision_function <- function(x, mu, sigma_inv, prior) {
# Ensure mu is a column vector
mu <- as.matrix(mu)
# Compute discriminant function
x %*% sigma_inv %*% mu - 0.5 * t(mu) %*% sigma_inv %*% mu + log(prior)
}
# Compute decision scores for test data
sigma_inv <- solve(cov_matrix)
# Apply decision function for each class
scores <- sapply(1:3, function(k) {
apply(as.matrix(test_data[, -1]), 1, function(x_row) {
lda_decision_function(x_row, class_means[[k]], sigma_inv, class_priors[k])
})
})
# Convert scores into predicted classes
predictions <- apply(scores, 1, which.max)
accuracy <- mean(predictions == test_data$Digit)
# Confusion matrix
confusion_matrix <- table(predictions, test_data$Digit)
# Check the lengths of predictions and test data labels
length(predictions)  # This should be equal to the number of rows in test_data
length(test_data$Digit)
# Corrected decision score computation
scores <- matrix(NA, nrow = nrow(test_data), ncol = 3)  # Initialize matrix for 3 classes
for (k in 1:3) {
# For each class (1, 7, 9), compute decision scores
scores[, k] <- apply(as.matrix(test_data[, -1]), 1, function(x_row) {
lda_decision_function(x_row, class_means[[k]], sigma_inv, class_priors[k])
})
}
# Check the dimensions of the scores matrix
dim(scores)  # Should be (number of test observations, number of classes)
# Convert scores into predicted classes
predictions <- apply(scores, 1, which.max)
# Check the length of predictions
length(predictions)  # Should match the number of rows in test_data
# Confusion matrix
if (length(predictions) == length(test_data$Digit)) {
confusion_matrix <- table(predictions, test_data$Digit)
print(confusion_matrix)
} else {
cat("Length mismatch: Predictions and test data labels are not the same length.\n")
}
# Check the first few rows of the scores matrix
head(scores)
# Load necessary libraries
library(MASS)
# Calculate the class means (mu_k) for each class
calculate_means <- function(data) {
tapply(1:nrow(data), data$Digit, function(idx) colMeans(data[idx, -1]))
}
# Function to estimate the shared covariance matrix (Sigma)
calculate_pooled_covariance <- function(data) {
cov(data[, -1])
}
# Estimate the class priors (pi_k)
calculate_class_priors <- function(data) {
table(data$Digit) / nrow(data)
}
# Function to compute the decision score for LDA
lda_decision_function <- function(x, mu, sigma_inv, prior) {
x %*% sigma_inv %*% mu - 0.5 * t(mu) %*% sigma_inv %*% mu + log(prior)
}
# Estimate parameters from the training data
class_means <- calculate_means(train_data)   # Mean vectors (mu_k)
cov_matrix <- calculate_pooled_covariance(train_data)  # Pooled covariance matrix (Sigma)
sigma_inv <- solve(cov_matrix)  # Inverse of covariance matrix (Sigma^{-1})
class_priors <- calculate_class_priors(train_data)  # Class priors (pi_k)
# Initialize an empty matrix to store decision scores for the test data
scores <- matrix(NA, nrow = nrow(test_data), ncol = 3)  # For 3 classes (1, 7, 9)
# Compute decision scores for each class
for (k in 1:3) {
# For each class, compute the decision score for all test observations
scores[, k] <- apply(as.matrix(test_data[, -1]), 1, function(x_row) {
lda_decision_function(x_row, class_means[[k]], sigma_inv, class_priors[k])
})
}
# Predict the class with the maximum score for each test observation
predictions <- apply(scores, 1, which.max)
# Calculate accuracy of predictions
accuracy <- mean(predictions == test_data$Digit)
# Generate the confusion matrix
confusion_matrix <- table(predictions, test_data$Digit)
# Split data into training and test sets
train_data <- mnist[1:1250, ]
test_data <- mnist[1251:2500, ]
# Filter training and test data for digits 1, 7, and 9
train_data_filtered <- train_data[train_data$Digit %in% c(1, 7, 9), ]
test_data_filtered <- test_data[test_data$Digit %in% c(1, 7, 9), ]
# Compute the variance for each pixel in the training set
pixel_variances <- apply(train_data_filtered[, -1], 2, var)
# Select the top 300 pixels based on the highest variance
top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]
# Subset the training and test data to keep only the top 300 pixels
train_data_top_pixels <- train_data_filtered[, c(1, top_pixels + 1)]  # +1 for the Digit column
test_data_top_pixels <- test_data_filtered[, c(1, top_pixels + 1)]
# Fit the LDA model on the training data
lda_model <- lda(Digit ~ ., data = train_data_top_pixels)
# Print the LDA model summary
summary(lda_model)
# Make predictions on the test data
lda_predictions <- predict(lda_model, newdata = test_data_top_pixels)
# Generate confusion matrix to evaluate predictions
confusion_matrix <- table(test_data_top_pixels$Digit, lda_predictions$class)
# Calculate and print accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Test Accuracy:", accuracy))
dim(train_data_filtered)
dim(test_data_filtered)
c(1, top_pixels + 1)
# inputs to download file
fileLocation <- "https://pjreddie.com/media/files/mnist_train.csv"
numRowsToDownload <- 2500
localFileName <- paste0("mnist_first", numRowsToDownload, ".RData")
# download the data and add column names
mnist <- read.csv(fileLocation, nrows = numRowsToDownload)
numColsMnist <- dim(mnist)[2]
colnames(mnist) <- c("Digit", paste("Pixel", seq(1:(numColsMnist - 1)), sep = ""))
# save file
# in the future we can read in from the local copy instead of having to redownload
save(mnist, file = localFileName)
# you can load the data with the following code
load(file = localFileName)
# Split data into training and test sets
train_data <- mnist[1:1250, ]
test_data <- mnist[1251:2500, ]
# Filter training and test data for digits 1, 7, and 9
train_data_filtered <- train_data[train_data$Digit %in% c(1, 7, 9), ]
test_data_filtered <- test_data[test_data$Digit %in% c(1, 7, 9), ]
# Compute the variance for each pixel in the training set
pixel_variances <- apply(train_data_filtered[, -1], 2, var)
# Select the top 300 pixels based on the highest variance
top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]
# Subset the training and test data to keep only the top 300 pixels
train_data_top_pixels <- train_data_filtered[, c(1, top_pixels + 1)]  # +1 for the Digit column
test_data_top_pixels <- test_data_filtered[, c(1, top_pixels + 1)]
# Fit the LDA model on the training data
lda_model <- lda(Digit ~ ., data = train_data_top_pixels)
# Print the LDA model summary
summary(lda_model)
# Make predictions on the test data
lda_predictions <- predict(lda_model, newdata = test_data_top_pixels)
# Generate confusion matrix to evaluate predictions
confusion_matrix <- table(test_data_top_pixels$Digit, lda_predictions$class)
# Calculate and print accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Test Accuracy:", accuracy))
# Load necessary libraries
library(MASS)
# Calculate the class means (mu_k) for each class
calculate_means <- function(data) {
tapply(1:nrow(data), data$Digit, function(idx) colMeans(data[idx, -1]))
}
# Function to estimate the shared covariance matrix (Sigma)
calculate_pooled_covariance <- function(data) {
cov(data[, -1])
}
# Estimate the class priors (pi_k)
calculate_class_priors <- function(data) {
table(data$Digit) / nrow(data)
}
# Function to compute the decision score for LDA
lda_decision_function <- function(x, mu, sigma_inv, prior) {
x %*% sigma_inv %*% mu - 0.5 * t(mu) %*% sigma_inv %*% mu + log(prior)
}
# Estimate parameters from the training data
class_means <- calculate_means(train_data)   # Mean vectors (mu_k)
cov_matrix <- calculate_pooled_covariance(train_data)  # Pooled covariance matrix (Sigma)
sigma_inv <- solve(cov_matrix)  # Inverse of covariance matrix (Sigma^{-1})
near_zero_variance_pixels <- which(apply(train_data_top_pixels[, -1], 2, var) < 1e-5)
near_zero_variance_pixels
ov_matrix
cov_matrix
class_means
View(train_data)
View(train_data_filtered)
View(test_data_filtered)
View(train_data_filtered)
View(train_data_top_pixels)
# Split data into training and test sets
train_data <- mnist[1:1250, ]
test_data <- mnist[1251:2500, ]
# Filter training and test data for digits 1, 7, and 9
train_data_filtered <- train_data[train_data$Digit %in% c(1, 7, 9), ]
test_data_filtered <- test_data[test_data$Digit %in% c(1, 7, 9), ]
# Compute the variance for each pixel in the training set
pixel_variances <- apply(train_data_filtered[, -1], 2, var)
# Select the top 300 pixels based on the highest variance
top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]
# Subset the training and test data to keep only the top 300 pixels
test_data <- train_data_filtered[, c(1, top_pixels + 1)]  # +1 for the Digit column
test_data <- test_data_filtered[, c(1, top_pixels + 1)]
# Fit the LDA model on the training data
lda_model <- lda(Digit ~ ., data = test_data)
# Print the LDA model summary
summary(lda_model)
# Make predictions on the test data
lda_predictions <- predict(lda_model, newdata = test_data)
# Generate confusion matrix to evaluate predictions
confusion_matrix <- table(test_data$Digit, lda_predictions$class)
# Calculate and print accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Test Accuracy:", accuracy))
# Split data into training and test sets
train_data <- mnist[1:1250, ]
test_data <- mnist[1251:2500, ]
# Filter training and test data for digits 1, 7, and 9
train_data_filtered <- train_data[train_data$Digit %in% c(1, 7, 9), ]
test_data_filtered <- test_data[test_data$Digit %in% c(1, 7, 9), ]
# Compute the variance for each pixel in the training set
pixel_variances <- apply(train_data_filtered[, -1], 2, var)
# Select the top 300 pixels based on the highest variance
top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]
# Subset the training and test data to keep only the top 300 pixels
test_data <- train_data_filtered[, c(1, top_pixels + 1)]  # +1 for the Digit column
test_data <- test_data_filtered[, c(1, top_pixels + 1)]
# Fit the LDA model on the training data
lda_model <- lda(Digit ~ ., data = train_data)
# Split data into training and test sets
train_data <- mnist[1:1250, ]
test_data <- mnist[1251:2500, ]
# Filter training and test data for digits 1, 7, and 9
train_data_filtered <- train_data[train_data$Digit %in% c(1, 7, 9), ]
test_data_filtered <- test_data[test_data$Digit %in% c(1, 7, 9), ]
# Compute the variance for each pixel in the training set
pixel_variances <- apply(train_data_filtered[, -1], 2, var)
# Select the top 300 pixels based on the highest variance
top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]
# Subset the training and test data to keep only the top 300 pixels
test_data <- train_data_filtered[, c(1, top_pixels + 1)]  # +1 for the Digit column
test_data <- test_data_filtered[, c(1, top_pixels + 1)]
# Fit the LDA model on the training data
lda_model <- lda(Digit ~ ., data = train_data)
# Split data into training and test sets
train_data <- mnist[1:1250, ]
test_data <- mnist[1251:2500, ]
# Filter training and test data for digits 1, 7, and 9
train_data_filtered <- train_data[train_data$Digit %in% c(1, 7, 9), ]
test_data_filtered <- test_data[test_data$Digit %in% c(1, 7, 9), ]
# Compute the variance for each pixel in the training set
pixel_variances <- apply(train_data_filtered[, -1], 2, var)
# Select the top 300 pixels based on the highest variance
top_pixels <- order(pixel_variances, decreasing = TRUE)[1:300]
# Subset the training and test data to keep only the top 300 pixels
train_data <- train_data_filtered[, c(1, top_pixels + 1)]  # +1 for the Digit column
test_data <- test_data_filtered[, c(1, top_pixels + 1)]
# Fit the LDA model on the training data
lda_model <- lda(Digit ~ ., data = train_data)
# Print the LDA model summary
summary(lda_model)
# Make predictions on the test data
lda_predictions <- predict(lda_model, newdata = test_data)
# Generate confusion matrix to evaluate predictions
confusion_matrix <- table(test_data$Digit, lda_predictions$class)
# Calculate and print accuracy
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Test Accuracy:", accuracy))
# Load necessary libraries
library(MASS)
# Calculate the class means (mu_k) for each class
calculate_means <- function(data) {
tapply(1:nrow(data), data$Digit, function(idx) colMeans(data[idx, -1]))
}
# Function to estimate the shared covariance matrix (Sigma)
calculate_pooled_covariance <- function(data) {
cov(data[, -1])
}
# Estimate the class priors (pi_k)
calculate_class_priors <- function(data) {
table(data$Digit) / nrow(data)
}
# Function to compute the decision score for LDA
lda_decision_function <- function(x, mu, sigma_inv, prior) {
x %*% sigma_inv %*% mu - 0.5 * t(mu) %*% sigma_inv %*% mu + log(prior)
}
# Estimate parameters from the training data
class_means <- calculate_means(train_data)   # Mean vectors (mu_k)
cov_matrix <- calculate_pooled_covariance(train_data)  # Pooled covariance matrix (Sigma)
sigma_inv <- solve(cov_matrix)  # Inverse of covariance matrix (Sigma^{-1})
class_priors <- calculate_class_priors(train_data)  # Class priors (pi_k)
# Initialize an empty matrix to store decision scores for the test data
scores <- matrix(NA, nrow = nrow(test_data), ncol = 3)  # For 3 classes (1, 7, 9)
# Compute decision scores for each class
for (k in 1:3) {
# For each class, compute the decision score for all test observations
scores[, k] <- apply(as.matrix(test_data[, -1]), 1, function(x_row) {
lda_decision_function(x_row, class_means[[k]], sigma_inv, class_priors[k])
})
}
# Predict the class with the maximum score for each test observation
predictions <- apply(scores, 1, which.max)
# Calculate accuracy of predictions
accuracy <- mean(predictions == test_data$Digit)
# Generate the confusion matrix
confusion_matrix <- table(predictions, test_data$Digit)
# Output results
cat("Accuracy:", accuracy, "\n")
cat("Confusion Matrix:\n")
print(confusion_matrix)
# Step 1: Fit the LDA model using the MASS package
lda_model_mass <- lda(Digit ~ ., data = test_data)
# Step 2: Make predictions on the test set
lda_predictions_mass <- predict(lda_model_mass, newdata = test_data)
# Step 3: Confusion matrix and accuracy
confusion_matrix_mass <- table(test_data$Digit, lda_predictions_mass$class)
accuracy_mass <- sum(diag(confusion_matrix_mass)) / sum(confusion_matrix_mass)
# Print results for LDA with MASS
print(paste("Test Accuracy (MASS lda()):", accuracy_mass))
print("Confusion Matrix (MASS lda()):")
print(confusion_matrix_mass)
# Compare with manual LDA results from part (b)
print(paste("Test Accuracy (Manual LDA):", results$accuracy))
# Load the MASS package
library(MASS)
# Fit the LDA model using the MASS lda() function
lda_model_mass <- lda(Digit ~ ., data = train_data)
# Make predictions on the test set
lda_predictions_mass <- predict(lda_model_mass, newdata = test_data)
# Generate confusion matrix to evaluate predictions
confusion_matrix_mass <- table(test_data$Digit, lda_predictions_mass$class)
# Calculate accuracy
accuracy_mass <- sum(diag(confusion_matrix_mass)) / sum(confusion_matrix_mass)
# Print the results
cat("Test Accuracy (MASS lda()):", accuracy_mass, "\n")
cat("Confusion Matrix (MASS lda()):\n")
print(confusion_matrix_mass)
# Compare with part (b)
cat("\nComparison with Part (b):\n")
cat("Accuracy in Part (b):", accuracy, "\n")
cat("Accuracy in Part (c) using lda():", accuracy_mass, "\n")
if (accuracy_mass > accuracy) {
cat("The accuracy using MASS lda() is higher.\n")
} else if (accuracy_mass < accuracy) {
cat("The accuracy using your custom LDA implementation is higher.\n")
} else {
cat("Both methods have the same accuracy.\n")
}
libaray(MASS)
library(MASS)
# load library
library(ISLR)
# load data
data(Carseats)
# set seed
set.seed(7)
# number of rows in entire dataset
n_Carseats <- dim(Carseats)[1]
# training set parameters
train_percentage <- 0.75
train_size <- floor(train_percentage*n_Carseats)
train_indices <- sample(x = 1:n_Carseats, size = train_size)
# separate dataset into train and test
train_Carseats <- Carseats[train_indices,]
test_Carseats <- Carseats[-train_indices,]
# Load necessary libraries
library(ISLR)
library(rpart)
library(rpart.plot)
# Load and prepare the data
data(Carseats)
set.seed(7)
# Define train-test split
n_Carseats <- dim(Carseats)[1]
train_percentage <- 0.75
train_size <- floor(train_percentage * n_Carseats)
train_indices <- sample(x = 1:n_Carseats, size = train_size)
# Split data into training and test sets
train_Carseats <- Carseats[train_indices, ]
test_Carseats <- Carseats[-train_indices, ]
# Fit a regression tree model to the training set
tree_model <- rpart(Sales ~ ., data = train_Carseats)
# Plot the regression tree
prp(tree_model)
# Predict sales on the test set
tree_predictions <- predict(tree_model, newdata = test_Carseats)
# Calculate the Mean-Squared Error (MSE) on the test data
mse_tree <- mean((tree_predictions - test_Carseats$Sales)^2)
cat("Test MSE (Unpruned Tree):", mse_tree, "\n")
# Identify observations with highest/lowest sales from tree splits
cat("Observations with highest sales are based on the splits of key features like ShelveLoc, Price, and CompPrice.")
# Set seed again and fit the model to keep consistency
set.seed(7)
# Perform cross-validation and find complexity parameter (cp) with minimum error + standard deviation
printcp(tree_model)  # View cross-validation results
cp_table <- tree_model$cptable
min_error <- min(cp_table[, "xerror"])
best_cp <- cp_table[which.min(cp_table[, "xerror"] + cp_table[, "xstd"] > min_error), "CP"]
# Prune the tree using the best complexity parameter
pruned_tree <- prune(tree_model, cp = best_cp)
# Plot the pruned tree
prp(pruned_tree)
# Predict using the pruned tree on the test set
pruned_predictions <- predict(pruned_tree, newdata = test_Carseats)
# Calculate the Mean-Squared Error (MSE) on the test data for the pruned tree
mse_pruned <- mean((pruned_predictions - test_Carseats$Sales)^2)
cat("Test MSE (Pruned Tree):", mse_pruned, "\n")
# Print the best complexity parameter
cat("Best complexity parameter for pruning:", best_cp, "\n")
